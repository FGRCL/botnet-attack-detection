{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7a56a10",
   "metadata": {},
   "source": [
    "# Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f92284f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import imblearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_decomposition import CCA\n",
    "from sklearn.decomposition import FastICA \n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from collections import Counter\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8b017d",
   "metadata": {},
   "source": [
    "# 2. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "206fdb2d",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Gaspipelinedatasetfull.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\marya\\OneDrive\\Desktop\\Machine Learning Course\\Fall 2022 COMP6321\\Final Project\\COMP6321Project.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/marya/OneDrive/Desktop/Machine%20Learning%20Course/Fall%202022%20COMP6321/Final%20Project/COMP6321Project.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Reference: https://sites.google.com/a/uah.edu/tommy-morris-uah/ics-data-sets\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/marya/OneDrive/Desktop/Machine%20Learning%20Course/Fall%202022%20COMP6321/Final%20Project/COMP6321Project.ipynb#W4sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/marya/OneDrive/Desktop/Machine%20Learning%20Course/Fall%202022%20COMP6321/Final%20Project/COMP6321Project.ipynb#W4sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# read contents of csv file\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/marya/OneDrive/Desktop/Machine%20Learning%20Course/Fall%202022%20COMP6321/Final%20Project/COMP6321Project.ipynb#W4sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m data_old \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m'\u001b[39;49m\u001b[39mGaspipelinedatasetfull.csv\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/marya/OneDrive/Desktop/Machine%20Learning%20Course/Fall%202022%20COMP6321/Final%20Project/COMP6321Project.ipynb#W4sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# adding header\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/marya/OneDrive/Desktop/Machine%20Learning%20Course/Fall%202022%20COMP6321/Final%20Project/COMP6321Project.ipynb#W4sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m#headerList = ['address', 'function', 'length', 'setpoint', 'gain', 'reset rate', 'deadband', 'cycle time', 'rate', 'system mode', 'control scheme', 'pump', 'solenoid', 'pressure measurement', 'crc rate', 'command response', 'time', 'binary result', 'categorized result', 'specific result']\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/marya/OneDrive/Desktop/Machine%20Learning%20Course/Fall%202022%20COMP6321/Final%20Project/COMP6321Project.ipynb#W4sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m headerList \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mcommand_address\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mresponse_address\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mcommand_memory\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mresponse_memory\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mcommand_memory_count\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mresponse_memory_count\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mcomm_read_function\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mcomm_write_fun\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mresp_read_fun\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mresp_write_fun\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39msub_function\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mcommand_length\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mresp_length\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mgain\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mreset\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mdeadband\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mcycletime\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mrate\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39msetpoint\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mcontrol_mode\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mcontrol_scheme\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mpump\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39msolenoid\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mcrc_rate\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mmeasurement\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mtime\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mresult\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\io\\parsers\\readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    665\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    666\u001b[0m     dialect,\n\u001b[0;32m    667\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    676\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[0;32m    677\u001b[0m )\n\u001b[0;32m    678\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 680\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\io\\parsers\\readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    572\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    574\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 575\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    577\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    578\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\io\\parsers\\readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    930\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    932\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 933\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\io\\parsers\\readers.py:1217\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1213\u001b[0m     mode \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1214\u001b[0m \u001b[39m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[0;32m   1215\u001b[0m \u001b[39m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[0;32m   1216\u001b[0m \u001b[39m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[1;32m-> 1217\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(  \u001b[39m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[0;32m   1218\u001b[0m     f,\n\u001b[0;32m   1219\u001b[0m     mode,\n\u001b[0;32m   1220\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1221\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1222\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m   1223\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[0;32m   1224\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1225\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1226\u001b[0m )\n\u001b[0;32m   1227\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1228\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\io\\common.py:789\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    784\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    785\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    786\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    787\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    788\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> 789\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[0;32m    790\u001b[0m             handle,\n\u001b[0;32m    791\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    792\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    793\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    794\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    795\u001b[0m         )\n\u001b[0;32m    796\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    797\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    798\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Gaspipelinedatasetfull.csv'"
     ]
    }
   ],
   "source": [
    "# Reference: https://sites.google.com/a/uah.edu/tommy-morris-uah/ics-data-sets\n",
    "\n",
    "# read contents of csv file\n",
    "data_old = pd.read_csv('Gaspipelinedatasetfull.csv')\n",
    "\n",
    "# adding header\n",
    "#headerList = ['address', 'function', 'length', 'setpoint', 'gain', 'reset rate', 'deadband', 'cycle time', 'rate', 'system mode', 'control scheme', 'pump', 'solenoid', 'pressure measurement', 'crc rate', 'command response', 'time', 'binary result', 'categorized result', 'specific result']\n",
    "headerList = ['command_address', 'response_address', 'command_memory', 'response_memory', 'command_memory_count', 'response_memory_count', 'comm_read_function', 'comm_write_fun', 'resp_read_fun', 'resp_write_fun', 'sub_function', 'command_length', 'resp_length', 'gain', 'reset', 'deadband', 'cycletime', 'rate', 'setpoint', 'control_mode', 'control_scheme', 'pump', 'solenoid', 'crc_rate', 'measurement', 'time', 'result']\n",
    "\n",
    "# converting data frame to csv\n",
    "data_old.to_csv(\"Gaspipelinedatasetfull.csv\", header=headerList, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daad1262",
   "metadata": {},
   "source": [
    "# 3. Separate features from label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2539fc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_old = data_old.loc[ : , data_old.columns != 'result']\n",
    "y_old = data_old['result']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9187ecce",
   "metadata": {},
   "source": [
    "# 4. Dataset Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895552b6",
   "metadata": {},
   "source": [
    "### 4.1 Check Missing values in features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d52784e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find missing values\n",
    "x_old.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5175ef93",
   "metadata": {},
   "source": [
    "### 4.2 Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49de7837",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_old_scaled = StandardScaler().fit_transform(x_old)\n",
    "\n",
    "print(\"Imbalanced data mean: \", x_old_scaled.mean())\n",
    "print(\"Imbalanced data std: \", x_old_scaled.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a46f06",
   "metadata": {},
   "source": [
    "### 4.3 Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f3c005",
   "metadata": {},
   "source": [
    "#### 4.3.1 PCA dimension reduction function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27667292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# each bar shows the explained variance percentage of individual components\n",
    "# the step plot shows the cumulative explained variance percentages\n",
    "    \n",
    "# def feature_selection_pca(x):\n",
    "pca = PCA(n_components=None)\n",
    "pca.fit(x_old_scaled)\n",
    "exp_var = pca.explained_variance_ratio_ * 100\n",
    "cum_exp_var = np.cumsum(exp_var)\n",
    "plt.bar(range(len(list(cum_exp_var))), exp_var, align='center', label='Individual explained variance')\n",
    "plt.step(range(len(list(cum_exp_var))), cum_exp_var, where='mid', label='Cumulative explained variance', color='red')\n",
    "plt.ylabel('Explained variance percentage')\n",
    "plt.xlabel('Principal component index')\n",
    "plt.xticks(np.arange(1, 14, 1))\n",
    "plt.legend(loc='best')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# return \n",
    "\n",
    "# feature_selection_pca(x_old_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2afd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a PCA object\n",
    "# make an instance of the Model\n",
    "\n",
    "def feature_selection_pca(data,x,y):\n",
    "    pca_95 = PCA(n_components=1, random_state=2020)\n",
    "    \n",
    "    # fit PCA on training set. Fitting PCA on the training set only\n",
    "    pca_95.fit(x)\n",
    "\n",
    "    # apply the mapping (transform) to both the training set and the test set\n",
    "    x_pca_95 = pca_95.transform(x)\n",
    "    \n",
    "    # create a pandas DataFrame using the values of all principal components \n",
    "    # and add the label column of the original dataset\n",
    "    data_pca = pd.DataFrame(x_pca_95, columns=['feature_1'])\n",
    "    data_pca['label1'] = data.result\n",
    "    #data_pca.head()\n",
    "    #print(data_pca.shape)\n",
    "    data_pca.to_csv('HMLIDS_91122_pca.csv', index=False)\n",
    "    selectedfeature_pca = data_pca['feature_1'].tolist()\n",
    "    \n",
    "    return selectedfeature_pca"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39851cb",
   "metadata": {},
   "source": [
    "#### 4.3.2 CCA dimension reduction function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88cb9dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CCA dimension reduction\n",
    "\n",
    "def feature_selection_cca(data,x,y):\n",
    "    cca = CCA(n_components=1)\n",
    "    cca.fit(x, y)\n",
    "    x_cca, y_cca = cca.transform(x, y)\n",
    "    #print(x_cca.shape)\n",
    "    # create a pandas DataFrame using the values of all principal components \n",
    "    # and add the label column of the original dataset\n",
    "    data_cca = pd.DataFrame(x_cca, columns=['feature_2'])\n",
    "    data_cca['label2'] = data.result\n",
    "    #data_cca.head()\n",
    "    #print(data_cca.shape)\n",
    "    data_cca.to_csv('HMLIDS_91122_cca.csv', index=False)\n",
    "    selectedfeature_cca = data_cca['feature_2'].tolist()\n",
    "    \n",
    "    return selectedfeature_cca"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0f1449",
   "metadata": {},
   "source": [
    "#### 4.3.3 ICA dimension reduction function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3bb1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ICA dimension reduction\n",
    "\n",
    "def feature_selection_ica(data,x,y):\n",
    "    ICA = FastICA(n_components=1, random_state=12) \n",
    "    x_ica=ICA.fit_transform(x)\n",
    "    #print(x_ica.shape)\n",
    "    \n",
    "    # create a pandas DataFrame using the values of all principal components \n",
    "    # and add the label column of the original dataset\n",
    "    data_ica = pd.DataFrame(x_ica, columns=['feature_3'])\n",
    "    data_ica['label3'] = data.result\n",
    "    #data_ica.head()\n",
    "    #print(data_ica.shape)\n",
    "    data_ica.to_csv('HMLIDS_91122_ica.csv', index=False)\n",
    "    selectedfeature_ica = data_ica['feature_3'].tolist()\n",
    "    \n",
    "    return selectedfeature_ica"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f84fabb",
   "metadata": {},
   "source": [
    "#### 4.3.4 Combine features from all the previous techniques "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35df1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all the previous techniques \n",
    "FS_pca_old = feature_selection_pca(data_old,x_old_scaled,y_old)\n",
    "FS_cca_old = feature_selection_cca(data_old,x_old_scaled,y_old)\n",
    "FS_ica_old = feature_selection_ica(data_old,x_old_scaled,y_old)\n",
    "\n",
    "data_old_FS = pd.DataFrame()\n",
    "data_old_FS['FS_pca'] = np.array(FS_pca_old)\n",
    "data_old_FS['FS_cca'] = np.array(FS_cca_old)\n",
    "data_old_FS['FS_ica'] = np.array(FS_ica_old)\n",
    "data_old_FS['label'] = y_old\n",
    "display(data_old_FS)\n",
    "data_old_FS.to_csv('HMLIDS_91122_old_FS.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3a6af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_old_FS.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d36248",
   "metadata": {},
   "source": [
    "# 5. Extract features & labels of normal & each attack type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99dc12d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### NORMAL\n",
    "data_old_FS_normal = data_old_FS.loc[(data_old_FS['label'] == 0)]\n",
    "## PCA\n",
    "x_old_FS_normal_pca = data_old_FS_normal.loc[ : , data_old_FS_normal.columns == 'FS_pca']\n",
    "y_old_FS_normal_pca = data_old_FS_normal['label']\n",
    "## CCA\n",
    "x_old_FS_normal_cca = data_old_FS_normal.loc[ : , data_old_FS_normal.columns == 'FS_cca']\n",
    "y_old_FS_normal_cca = data_old_FS_normal['label']\n",
    "## ICA\n",
    "x_old_FS_normal_ica = data_old_FS_normal.loc[ : , data_old_FS_normal.columns == 'FS_ica']\n",
    "y_old_FS_normal_ica = data_old_FS_normal['label']\n",
    "\n",
    "\n",
    "###### NMRI\n",
    "data_old_FS_NMRI = data_old_FS.loc[(data_old_FS['label'] == 1)]\n",
    "## PCA\n",
    "x_old_FS_NMRI_pca = data_old_FS_NMRI.loc[ : , data_old_FS_NMRI.columns == 'FS_pca']\n",
    "y_old_FS_NMRI_pca = data_old_FS_NMRI['label']\n",
    "## CCA\n",
    "x_old_FS_NMRI_cca = data_old_FS_NMRI.loc[ : , data_old_FS_NMRI.columns == 'FS_cca']\n",
    "y_old_FS_NMRI_cca = data_old_FS_NMRI['label']\n",
    "## ICA\n",
    "x_old_FS_NMRI_ica = data_old_FS_NMRI.loc[ : , data_old_FS_NMRI.columns == 'FS_ica']\n",
    "y_old_FS_NMRI_ica = data_old_FS_NMRI['label']\n",
    "\n",
    "\n",
    "###### CMRI\n",
    "data_old_FS_CMRI = data_old_FS.loc[(data_old_FS['label'] == 2)]\n",
    "## PCA\n",
    "x_old_FS_CMRI_pca = data_old_FS_CMRI.loc[ : , data_old_FS_CMRI.columns == 'FS_pca']\n",
    "y_old_FS_CMRI_pca = data_old_FS_CMRI['label']\n",
    "## CCA\n",
    "x_old_FS_CMRI_cca = data_old_FS_CMRI.loc[ : , data_old_FS_CMRI.columns == 'FS_cca']\n",
    "y_old_FS_CMRI_cca = data_old_FS_CMRI['label']\n",
    "## ICA\n",
    "x_old_FS_CMRI_ica = data_old_FS_CMRI.loc[ : , data_old_FS_CMRI.columns == 'FS_ica']\n",
    "y_old_FS_CMRI_ica = data_old_FS_CMRI['label']\n",
    "\n",
    "\n",
    "###### MSCI\n",
    "data_old_FS_MSCI = data_old_FS.loc[(data_old_FS['label'] == 2)]\n",
    "## PCA\n",
    "x_old_FS_MSCI_pca = data_old_FS_MSCI.loc[ : , data_old_FS_MSCI.columns == 'FS_pca']\n",
    "y_old_FS_MSCI_pca = data_old_FS_MSCI['label']\n",
    "## CCA\n",
    "x_old_FS_MSCI_cca = data_old_FS_MSCI.loc[ : , data_old_FS_MSCI.columns == 'FS_cca']\n",
    "y_old_FS_MSCI_cca = data_old_FS_MSCI['label']\n",
    "## ICA\n",
    "x_old_FS_MSCI_ica = data_old_FS_MSCI.loc[ : , data_old_FS_MSCI.columns == 'FS_ica']\n",
    "y_old_FS_MSCI_ica = data_old_FS_MSCI['label']\n",
    "\n",
    "\n",
    "###### MPCI\n",
    "data_old_FS_MPCI = data_old_FS.loc[(data_old_FS['label'] == 3)]\n",
    "## PCA\n",
    "x_old_FS_MPCI_pca = data_old_FS_MPCI.loc[ : , data_old_FS_MPCI.columns == 'FS_pca']\n",
    "y_old_FS_MPCI_pca = data_old_FS_MPCI['label']\n",
    "## CCA\n",
    "x_old_FS_MPCI_cca = data_old_FS_MPCI.loc[ : , data_old_FS_MPCI.columns == 'FS_cca']\n",
    "y_old_FS_MPCI_cca = data_old_FS_MPCI['label']\n",
    "## ICA\n",
    "x_old_FS_MPCI_ica = data_old_FS_MPCI.loc[ : , data_old_FS_MPCI.columns == 'FS_ica']\n",
    "y_old_FS_MPCI_ica = data_old_FS_MPCI['label']\n",
    "\n",
    "\n",
    "###### MFCI\n",
    "data_old_FS_MFCI = data_old_FS.loc[(data_old_FS['label'] == 4)]\n",
    "## PCA\n",
    "x_old_FS_MFCI_pca = data_old_FS_MFCI.loc[ : , data_old_FS_MFCI.columns == 'FS_pca']\n",
    "y_old_FS_MFCI_pca = data_old_FS_MFCI['label']\n",
    "## CCA\n",
    "x_old_FS_MFCI_cca = data_old_FS_MFCI.loc[ : , data_old_FS_MFCI.columns == 'FS_cca']\n",
    "y_old_FS_MFCI_cca = data_old_FS_MFCI['label']\n",
    "## ICA\n",
    "x_old_FS_MFCI_ica = data_old_FS_MFCI.loc[ : , data_old_FS_MFCI.columns == 'FS_ica']\n",
    "y_old_FS_MFCI_ica = data_old_FS_MFCI['label']\n",
    "\n",
    "\n",
    "###### DoS\n",
    "data_old_FS_DoS = data_old_FS.loc[(data_old_FS['label'] == 1)]\n",
    "## PCA\n",
    "x_old_FS_DoS_pca = data_old_FS_DoS.loc[ : , data_old_FS_DoS.columns == 'FS_pca']\n",
    "y_old_FS_DoS_pca = data_old_FS_DoS['label']\n",
    "## CCA\n",
    "x_old_FS_DoS_cca = data_old_FS_DoS.loc[ : , data_old_FS_DoS.columns == 'FS_cca']\n",
    "y_old_FS_DoS_cca = data_old_FS_DoS['label']\n",
    "## ICA\n",
    "x_old_FS_DoS_ica = data_old_FS_DoS.loc[ : , data_old_FS_DoS.columns == 'FS_ica']\n",
    "y_old_FS_DoS_ica = data_old_FS_DoS['label']\n",
    "\n",
    "\n",
    "###### Recon\n",
    "data_old_FS_Recon = data_old_FS.loc[(data_old_FS['label'] == 1)]\n",
    "## PCA\n",
    "x_old_FS_Recon_pca = data_old_FS_Recon.loc[ : , data_old_FS_Recon.columns == 'FS_pca']\n",
    "y_old_FS_Recon_pca = data_old_FS_Recon['label']\n",
    "## CCA\n",
    "x_old_FS_Recon_cca = data_old_FS_Recon.loc[ : , data_old_FS_Recon.columns == 'FS_cca']\n",
    "y_old_FS_Recon_cca = data_old_FS_Recon['label']\n",
    "## ICA\n",
    "x_old_FS_Recon_ica = data_old_FS_Recon.loc[ : , data_old_FS_Recon.columns == 'FS_ica']\n",
    "y_old_FS_Recon_ica = data_old_FS_Recon['label']\n",
    "\n",
    "\n",
    "\n",
    "###### Aggregated Attacks\n",
    "data_old_FS_agg_attacks = data_old_FS.loc[(data_old_FS['label'] != 0)]\n",
    "## PCA\n",
    "x_old_FS_agg_attacks_pca = data_old_FS_agg_attacks.loc[ : , data_old_FS_agg_attacks.columns == 'FS_pca']\n",
    "y_old_FS_agg_attacks_pca = data_old_FS_agg_attacks['label']\n",
    "## CCA\n",
    "x_old_FS_agg_attacks_cca = data_old_FS_agg_attacks.loc[ : , data_old_FS_agg_attacks.columns == 'FS_cca']\n",
    "y_old_FS_agg_attacks_cca = data_old_FS_agg_attacks['label']\n",
    "## ICA\n",
    "x_old_FS_agg_attacks_ica = data_old_FS_agg_attacks.loc[ : , data_old_FS_agg_attacks.columns == 'FS_ica']\n",
    "y_old_FS_agg_attacks_ica = data_old_FS_agg_attacks['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2852f6c2",
   "metadata": {},
   "source": [
    "# 6. Class Balancing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969ea98e",
   "metadata": {},
   "source": [
    "# 6.1 Balancing aggregated attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bed7bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def overSamplingTech(x, y):\n",
    "    o = RandomOverSampler()\n",
    "    x_t, y_t = o.fit_resample(x, y)\n",
    "    return x_t, y_t\n",
    "\n",
    "x_balanced_FS_agg_attacks_pca, y_balanced_FS_agg_attacks_pca = overSamplingTech(x_old_FS_agg_attacks_pca, y_old_FS_agg_attacks_pca)\n",
    "x_balanced_FS_agg_attacks_cca, y_balanced_FS_agg_attacks_cca = overSamplingTech(x_old_FS_agg_attacks_cca, y_old_FS_agg_attacks_cca)\n",
    "x_balanced_FS_agg_attacks_ica, y_balanced_FS_agg_attacks_ica = overSamplingTech(x_old_FS_agg_attacks_ica, y_old_FS_agg_attacks_ica)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37724c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_y_old = []\n",
    "list_y_old.append((y_old_FS_agg_attacks_pca.shape)[0])\n",
    "list_y_old.append((y_old_FS_agg_attacks_cca.shape)[0])\n",
    "list_y_old.append((y_old_FS_agg_attacks_ica.shape)[0])\n",
    "list_y_balanced = []\n",
    "list_y_balanced.append((y_balanced_FS_agg_attacks_pca.shape)[0])\n",
    "list_y_balanced.append((y_balanced_FS_agg_attacks_cca.shape)[0])\n",
    "list_y_balanced.append((y_balanced_FS_agg_attacks_ica.shape)[0])\n",
    "    \n",
    "# initialize data of lists\n",
    "data_ = {'Before Balancing': list_y_old,\n",
    "        'After Balancing': list_y_balanced}\n",
    "index = ['pca attacks', 'cca attacks', 'ica attacks'] \n",
    "\n",
    "# Creates pandas DataFrame\n",
    "df = pd.DataFrame(data = data_, index=index)\n",
    "df.plot.bar(title='Dataset attacks comparison before and after Balancing')\n",
    "plt.show(block=True)\n",
    "\n",
    "print(list_y_old)\n",
    "print(list_y_balanced)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d22fae",
   "metadata": {},
   "source": [
    "# 5. Binary labels Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd19372d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_old_FS_agg_attacks_pca_binary = y_old_FS_agg_attacks_pca.copy()\n",
    "y_old_FS_agg_attacks_pca_binary.iloc[:] = 1\n",
    "\n",
    "y_old_FS_agg_attacks_cca_binary = y_old_FS_agg_attacks_cca.copy()\n",
    "y_old_FS_agg_attacks_cca_binary.iloc[:] = 1\n",
    "\n",
    "y_old_FS_agg_attacks_ica_binary = y_old_FS_agg_attacks_ica.copy()\n",
    "y_old_FS_agg_attacks_ica_binary.iloc[:] = 1\n",
    "\n",
    "\n",
    "y_balanced_FS_agg_attacks_pca_binary = y_balanced_FS_agg_attacks_pca.copy()\n",
    "y_balanced_FS_agg_attacks_pca_binary.iloc[:] = 1\n",
    "\n",
    "y_balanced_FS_agg_attacks_cca_binary = y_balanced_FS_agg_attacks_cca.copy()\n",
    "y_balanced_FS_agg_attacks_cca_binary.iloc[:] = 1\n",
    "\n",
    "y_balanced_FS_agg_attacks_ica_binary = y_balanced_FS_agg_attacks_ica.copy()\n",
    "y_balanced_FS_agg_attacks_ica_binary.iloc[:] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f7a12f",
   "metadata": {},
   "source": [
    "# 6.1 Balancing aggregated attacks with normal attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9742e628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add balanced aggregated attacks features & labels to normal instances \n",
    "## PCA\n",
    "\n",
    "x_old_FS_normal_agg_pca = pd.concat([x_old_FS_normal_pca, x_balanced_FS_agg_attacks_pca])\n",
    "y_old_FS_normal_agg_pca = pd.concat([y_old_FS_normal_pca, y_balanced_FS_agg_attacks_pca_binary])\n",
    "\n",
    "## CCA\n",
    "x_old_FS_normal_agg_cca = pd.concat([x_old_FS_normal_cca, x_balanced_FS_agg_attacks_cca])\n",
    "y_old_FS_normal_agg_cca = pd.concat([y_old_FS_normal_pca, y_balanced_FS_agg_attacks_cca_binary])\n",
    "\n",
    "## ICA\n",
    "x_old_FS_normal_agg_ica = pd.concat([x_old_FS_normal_ica, x_balanced_FS_agg_attacks_ica])\n",
    "y_old_FS_normal_agg_ica = pd.concat([y_old_FS_normal_pca, y_balanced_FS_agg_attacks_ica_binary])\n",
    "\n",
    "x_balanced_FS_normal_agg_pca, y_balanced_FS_normal_agg_pca = overSamplingTech(x_old_FS_normal_agg_pca, y_old_FS_normal_agg_pca)\n",
    "x_balanced_FS_normal_agg_cca, y_balanced_FS_normal_agg_cca = overSamplingTech(x_old_FS_normal_agg_cca, y_old_FS_normal_agg_cca)\n",
    "x_balanced_FS_normal_agg_ica, y_balanced_FS_normal_agg_ica = overSamplingTech(x_old_FS_normal_agg_ica, y_old_FS_normal_agg_ica)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a8d751",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_y_old_binary = []\n",
    "list_y_old_binary.append((y_old_FS_normal_agg_pca.shape)[0])\n",
    "list_y_old_binary.append((y_old_FS_normal_agg_cca.shape)[0])\n",
    "list_y_old_binary.append((y_old_FS_normal_agg_ica.shape)[0])\n",
    "list_y_balanced_binary = []\n",
    "list_y_balanced_binary.append((y_balanced_FS_agg_attacks_pca_binary.shape)[0])\n",
    "list_y_balanced_binary.append((y_balanced_FS_agg_attacks_cca_binary.shape)[0])\n",
    "list_y_balanced_binary.append((y_balanced_FS_agg_attacks_ica_binary.shape)[0])\n",
    "    \n",
    "# initialize data of lists\n",
    "data_ = {'Before Balancing': list_y_old_binary,\n",
    "        'After Balancing': list_y_balanced_binary}\n",
    "index = ['pca instances', 'cca instances', 'ica instances'] \n",
    "\n",
    "# Creates pandas DataFrame\n",
    "df = pd.DataFrame(data = data_, index=index)\n",
    "df.plot.bar(title='Dataset comparison before and after Balancing')\n",
    "plt.show(block=True)\n",
    "\n",
    "print(list_y_old_binary)\n",
    "print(list_y_balanced_binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13963005",
   "metadata": {},
   "source": [
    "# Splitting data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934b9636",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create training and testing sets\n",
    "# Split dataset into training set and test set\n",
    "# 70% training and 30% test\n",
    "\n",
    "# for imbalanced data\n",
    "x_train_old_pca, x_test_old_pca, y_train_old_pca, y_test_old_pca = train_test_split(x_old_FS_normal_agg_pca, y_old_FS_normal_agg_pca, test_size=0.3) \n",
    "x_train_old_cca, x_test_old_cca, y_train_old_cca, y_test_old_cca = train_test_split(x_old_FS_normal_agg_cca, y_old_FS_normal_agg_cca, test_size=0.3) \n",
    "x_train_old_ica, x_test_old_ica, y_train_old_ica, y_test_old_ica = train_test_split(x_old_FS_normal_agg_ica, y_old_FS_normal_agg_ica, test_size=0.3) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ced171f",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f308d880",
   "metadata": {},
   "source": [
    "## 1. KNN Classification & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0cb57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import knearest neighbors Classifier model\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Create KNN Classifier\n",
    "knn_old_pca = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_old_cca = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_old_ica = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Train the model using the training sets\n",
    "knn_old_pca.fit(x_train_old_pca, y_train_old_pca)\n",
    "knn_old_cca.fit(x_train_old_cca, y_train_old_cca)\n",
    "knn_old_ica.fit(x_train_old_ica, y_train_old_ica)\n",
    "\n",
    "# Predict the response for test dataset\n",
    "y_pred_old_pca = knn_old_pca.predict(x_test_old_pca)\n",
    "y_pred_old_cca = knn_old_cca.predict(x_test_old_cca)\n",
    "y_pred_old_ica = knn_old_ica.predict(x_test_old_ica)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffdd212c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation for k=5\n",
    "print(classification_report(y_test_old_pca, y_pred_old_pca))\n",
    "confusion_matrix_knn_pca = metrics.confusion_matrix(y_pred_old_pca,y_test_old_pca)\n",
    "cm_display_knn_pca = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix_knn_pca, display_labels = [False, True])\n",
    "cm_display_knn_pca.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3035a4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test_old_cca, y_pred_old_cca))\n",
    "confusion_matrix_knn_cca = metrics.confusion_matrix(y_pred_old_cca,y_test_old_cca)\n",
    "cm_display_knn_cca = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix_knn_cca, display_labels = [False, True])\n",
    "cm_display_knn_cca.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc7c96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test_old_ica, y_pred_old_ica))\n",
    "confusion_matrix_knn_ica = metrics.confusion_matrix(y_pred_old_ica,y_test_old_ica)\n",
    "cm_display_knn_ica = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix_knn_ica, display_labels = [False, True])\n",
    "cm_display_knn_ica.plot()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "d9729929de967187b71e472d041d61c0af878e283b0ae75b1af4b3be5f97f21a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
